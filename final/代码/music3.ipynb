{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "66c8f0db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_age</th>\n",
       "      <th>user_gender</th>\n",
       "      <th>user_province</th>\n",
       "      <th>user_city</th>\n",
       "      <th>user_introduce</th>\n",
       "      <th>comment</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>praise</th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>new_user_id</th>\n",
       "      <th>province_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>w安默拉w</td>\n",
       "      <td>2033412777</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>370000</td>\n",
       "      <td>371300.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>第一次听以为是“一生反复一场大无畏梦境”，特别惊艳，后来看到原句才发现是“奔赴”，又觉得奔赴...</td>\n",
       "      <td>6.040284e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-01-15 08:41:00</td>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>2033412777</td>\n",
       "      <td>山东省</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>橘生又落valentia</td>\n",
       "      <td>3727270134</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>自在随心，想唱什么就唱什么～</td>\n",
       "      <td>怀念一波入坑曲[多多大哭]</td>\n",
       "      <td>6.040167e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-01-15 01:48:00</td>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>3727270134</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>橘生又落valentia</td>\n",
       "      <td>3727270134</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>自在随心，想唱什么就唱什么～</td>\n",
       "      <td>@山风没疯 哈哈哈哈哈哈哈哈哈哈（）</td>\n",
       "      <td>6.040164e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-01-15 01:48:00</td>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>3727270134</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>竹苑Cecilia</td>\n",
       "      <td>6329599584</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>360000</td>\n",
       "      <td>361000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>情绪内耗就来听琉璃真的可以治愈我</td>\n",
       "      <td>6.037419e+09</td>\n",
       "      <td>2</td>\n",
       "      <td>2024-01-10 23:23:00</td>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>23</td>\n",
       "      <td>6329599584</td>\n",
       "      <td>江西省</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>清风夜水寒</td>\n",
       "      <td>2073414099</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>有疗愈效果，亲测</td>\n",
       "      <td>6.037348e+09</td>\n",
       "      <td>6</td>\n",
       "      <td>2024-01-10 21:10:00</td>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>21</td>\n",
       "      <td>2073414099</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>乂肀夂</td>\n",
       "      <td>1824914947</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>330000</td>\n",
       "      <td>330300.0</td>\n",
       "      <td>……想死</td>\n",
       "      <td>已经……不是三年了，是四年了……</td>\n",
       "      <td>6.037275e+09</td>\n",
       "      <td>4</td>\n",
       "      <td>2024-01-10 17:53:00</td>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>17</td>\n",
       "      <td>1824914947</td>\n",
       "      <td>浙江省</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>发雨呆</td>\n",
       "      <td>42012486</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>Trance in that rain.</td>\n",
       "      <td>三年了重听这首还是湿润双眸，“偏这人间要苦笑静穆风月顽冥”</td>\n",
       "      <td>6.037270e+09</td>\n",
       "      <td>2</td>\n",
       "      <td>2024-01-10 17:42:00</td>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>17</td>\n",
       "      <td>42012486</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>月亮来了也不晚安</td>\n",
       "      <td>1439650765</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>230000</td>\n",
       "      <td>230700.0</td>\n",
       "      <td>别远离我_</td>\n",
       "      <td>好好听</td>\n",
       "      <td>6.036967e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-01-09 22:57:00</td>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>22</td>\n",
       "      <td>1439650765</td>\n",
       "      <td>黑龙江省</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>道静玄</td>\n",
       "      <td>590932819</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>820000</td>\n",
       "      <td>820100.0</td>\n",
       "      <td>独与天地精神往来</td>\n",
       "      <td>这首歌真的有够惊艳！</td>\n",
       "      <td>6.036281e+09</td>\n",
       "      <td>5</td>\n",
       "      <td>2024-01-08 15:49:00</td>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>590932819</td>\n",
       "      <td>澳门特别行政区</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>啊哈ixta</td>\n",
       "      <td>1441175035</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>340000</td>\n",
       "      <td>340300.0</td>\n",
       "      <td>彷徨在巴黎街头，我不想回家，因为你不在家，便没有家  —雾都千寻</td>\n",
       "      <td>愿你此生尽兴，赤诚善良</td>\n",
       "      <td>6.034632e+09</td>\n",
       "      <td>2</td>\n",
       "      <td>2024-01-06 10:48:00</td>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>1441175035</td>\n",
       "      <td>安徽省</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_name     user_id  user_age  user_gender  user_province  user_city  \\\n",
       "0         w安默拉w  2033412777         0            2         370000   371300.0   \n",
       "1  橘生又落valentia  3727270134         0            0              0      100.0   \n",
       "2  橘生又落valentia  3727270134         0            0              0      100.0   \n",
       "3     竹苑Cecilia  6329599584         0            2         360000   361000.0   \n",
       "4         清风夜水寒  2073414099         0            0              0      100.0   \n",
       "5           乂肀夂  1824914947        18            2         330000   330300.0   \n",
       "6           发雨呆    42012486         0            0              0      100.0   \n",
       "7      月亮来了也不晚安  1439650765         0            2         230000   230700.0   \n",
       "8           道静玄   590932819         0            1         820000   820100.0   \n",
       "9        啊哈ixta  1441175035        34            1         340000   340300.0   \n",
       "\n",
       "                     user_introduce  \\\n",
       "0                               NaN   \n",
       "1                    自在随心，想唱什么就唱什么～   \n",
       "2                    自在随心，想唱什么就唱什么～   \n",
       "3                               NaN   \n",
       "4                               NaN   \n",
       "5                              ……想死   \n",
       "6              Trance in that rain.   \n",
       "7                             别远离我_   \n",
       "8                          独与天地精神往来   \n",
       "9  彷徨在巴黎街头，我不想回家，因为你不在家，便没有家  —雾都千寻   \n",
       "\n",
       "                                             comment    comment_id  praise  \\\n",
       "0  第一次听以为是“一生反复一场大无畏梦境”，特别惊艳，后来看到原句才发现是“奔赴”，又觉得奔赴...  6.040284e+09       0   \n",
       "1                                      怀念一波入坑曲[多多大哭]  6.040167e+09       0   \n",
       "2                                 @山风没疯 哈哈哈哈哈哈哈哈哈哈（）  6.040164e+09       0   \n",
       "3                                   情绪内耗就来听琉璃真的可以治愈我  6.037419e+09       2   \n",
       "4                                           有疗愈效果，亲测  6.037348e+09       6   \n",
       "5                                   已经……不是三年了，是四年了……  6.037275e+09       4   \n",
       "6                      三年了重听这首还是湿润双眸，“偏这人间要苦笑静穆风月顽冥”  6.037270e+09       2   \n",
       "7                                                好好听  6.036967e+09       1   \n",
       "8                                         这首歌真的有够惊艳！  6.036281e+09       5   \n",
       "9                                        愿你此生尽兴，赤诚善良  6.034632e+09       2   \n",
       "\n",
       "                  date  year  month  day  hour  new_user_id province_name  \n",
       "0  2024-01-15 08:41:00  2024      1   15     8   2033412777           山东省  \n",
       "1  2024-01-15 01:48:00  2024      1   15     1   3727270134           NaN  \n",
       "2  2024-01-15 01:48:00  2024      1   15     1   3727270134           NaN  \n",
       "3  2024-01-10 23:23:00  2024      1   10    23   6329599584           江西省  \n",
       "4  2024-01-10 21:10:00  2024      1   10    21   2073414099           NaN  \n",
       "5  2024-01-10 17:53:00  2024      1   10    17   1824914947           浙江省  \n",
       "6  2024-01-10 17:42:00  2024      1   10    17     42012486           NaN  \n",
       "7  2024-01-09 22:57:00  2024      1    9    22   1439650765          黑龙江省  \n",
       "8  2024-01-08 15:49:00  2024      1    8    15    590932819       澳门特别行政区  \n",
       "9  2024-01-06 10:48:00  2024      1    6    10   1441175035           安徽省  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"D:/total_已探索.csv\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa64567",
   "metadata": {},
   "source": [
    "# 数据建模"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cad2089",
   "metadata": {},
   "source": [
    "## 1.词云制作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c7dc51d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<wordcloud.wordcloud.WordCloud at 0x29caae4c7c0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jieba\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "str = open(\"D:/total_lyric.txt\",\"r\",encoding=\"UTF-8\").read().replace(\" \",\"\").replace(\":\",\"\").replace(\"\\n\",\"\").replace(\": \",\"\")\n",
    "list1 = jieba.lcut(str)\n",
    "# 去除停用词\n",
    "stopwords = {'的','作曲','作词','编曲','我', '你','灰原','又','在','了','不','是'}  \n",
    "filtered_words = [word for word in list1 if word not in stopwords]\n",
    "\n",
    "lists = \" \".join(filtered_words)\n",
    "\n",
    "# # 指定云词的模板\n",
    "# image = np.array(Image.open(\"qq.jpg\"))\n",
    "\n",
    "# 使用WordCloud进行云词的展示\n",
    "wc = WordCloud(font_path=\"msyh.ttc\", width=800, height=400, background_color=\"white\")\n",
    "wc.generate(lists)\n",
    "\n",
    "# 绘制,可以不用绘制直接保存图片\n",
    "# plt.imshow(wc)\n",
    "# plt.axis(\"off\")\n",
    "# plt.show()\n",
    "\n",
    "# 保存文件\n",
    "wc.to_file(\"ciyun.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34e64cd",
   "metadata": {},
   "source": [
    "## 2.LDA主题模型分析"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385f8e12",
   "metadata": {},
   "source": [
    "挖掘评论区文本中潜在主题，提取评论区用户关注点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bc8bc615",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1090d5",
   "metadata": {},
   "source": [
    "### 1.数据清洗和分词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "661e66e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       第一次 听 以为 是   一生 反复 一场 大无畏 梦境   特别 惊艳   后来 看到 原...\n",
      "1                                     怀念 一波入 坑曲   多多 大哭  \n",
      "2                                  山风 没疯   哈哈哈哈 哈哈哈 哈哈哈  \n",
      "3                               情绪 内耗 就 来 听 琉璃 真的 可以 治愈 我\n",
      "4                                            有疗 愈 效果   亲测\n",
      "                              ...                        \n",
      "8161                                              苍凉 的 光荣\n",
      "8162    第一次 听 是 初一 上 学期   那 时候 我 没有 网易 云   是 在 华为 音乐 听...\n",
      "8163                                         我 也 是 这么 来 的\n",
      "8164                          很 幸运   这些 年 我们 每次 放假 都 会 见面\n",
      "8165                        我 爱 苍生   也 爱 一人   我 爱 东方 青苍  \n",
      "Name: cut, Length: 8166, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#用正则表达式和jieba对内容进行清洗和分词\n",
    "pattern = u'[\\\\s\\\\d,.<>/?:;\\'\\\"[\\\\]{}()\\\\|~!\\t\"@#$%^&*\\\\-_=+a-zA-Z，。\\n《》、？：；“”‘’｛｝【】（）…￥！—┄－]+'\n",
    "df['cut'] = df['comment'].apply(lambda x: re.sub(pattern, ' ', x))\n",
    "df['cut'] = df['cut'].apply(lambda x: \" \".join(jieba.lcut(x)))\n",
    "print(df['cut'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700a64d7",
   "metadata": {},
   "source": [
    "### 2.使用TF-IDF构造词频矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "188395f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      一一对应   一七   一万  一万个  一万年  一万遍  一上午   一下  一下子  一不小心  ...  鼓起勇气   鼬佐   鼻头  \\\n",
      "0      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  ...   0.0  0.0  0.0   \n",
      "1      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  ...   0.0  0.0  0.0   \n",
      "2      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  ...   0.0  0.0  0.0   \n",
      "3      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  ...   0.0  0.0  0.0   \n",
      "4      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  ...   0.0  0.0  0.0   \n",
      "...    ...  ...  ...  ...  ...  ...  ...  ...  ...   ...  ...   ...  ...  ...   \n",
      "8161   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  ...   0.0  0.0  0.0   \n",
      "8162   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  ...   0.0  0.0  0.0   \n",
      "8163   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  ...   0.0  0.0  0.0   \n",
      "8164   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  ...   0.0  0.0  0.0   \n",
      "8165   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  ...   0.0  0.0  0.0   \n",
      "\n",
      "       鼻子   鼻孔   鼻祖   鼻音   齐名  龙战士   龙钟  \n",
      "0     0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "1     0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "2     0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "3     0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "4     0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "...   ...  ...  ...  ...  ...  ...  ...  \n",
      "8161  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "8162  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "8163  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "8164  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "8165  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "\n",
      "[8166 rows x 11815 columns]\n"
     ]
    }
   ],
   "source": [
    "# 1.构造 TF-IDF\n",
    "tf_idf_vectorizer = TfidfVectorizer()\n",
    "tf_idf = tf_idf_vectorizer.fit_transform(df['cut'])\n",
    "\n",
    "# 2.特征词列表\n",
    "feature_names = tf_idf_vectorizer.get_feature_names_out()\n",
    "\n",
    "# 3.将特征矩阵转换为 pandas DataFrame\n",
    "matrix = tf_idf.toarray()\n",
    "feature_names_df = pd.DataFrame(matrix,columns=feature_names)\n",
    "print(feature_names_df)\n",
    "\n",
    "#特征单词列表，仅针对词，单个字不计算入内"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f42e3bd",
   "metadata": {},
   "source": [
    "得到特征单词列表"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89688e59",
   "metadata": {},
   "source": [
    "### 3.将矩阵放入LDA模型进行训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b4b9fd59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(learning_method='online', learning_offset=50.0,\n",
       "                          max_iter=50, n_components=5, random_state=0)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 选定的主题数,也就是把所有特征词划分为5个主题\n",
    "n_topics = 5\n",
    "#定义LDA对象\n",
    "lda = LatentDirichletAllocation(\n",
    "    n_components=n_topics, max_iter=50,#最大迭代次数\n",
    "    learning_method='online',#采样方法\n",
    "    learning_offset=50.,#控制批量更新的速度和幅度\n",
    "    random_state=0) #随机种子以确保每次执行主题建模时输出结果一致\n",
    "# 核心，将TF-IDF 矩阵放入到LDA模型中\n",
    "lda.fit(tf_idf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe98ccb",
   "metadata": {},
   "source": [
    "想要得到：\n",
    "1.每一个主题的前n个主题词是什么\n",
    "2.每一个评论属于每一个主题的概率是多大"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fd9d926c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#两个函数对结果进行处理\n",
    "#1\n",
    "# 要输出的每个主题的前 n_top_words 个主题词数\n",
    "n_top_words = 50\n",
    "def top_words_data_frame(model: LatentDirichletAllocation, #一个训练好的LDA模型对象\n",
    "                         tf_idf_vectorizer: TfidfVectorizer, #一个已经训练好的文本向量化对象\n",
    "                         n_top_words: int) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    feature_names = tf_idf_vectorizer.get_feature_names_out()\n",
    "    for topic in model.components_:\n",
    "        top_words = [feature_names[i]\n",
    "                     for i in topic.argsort()[:-n_top_words - 1:-1]]\n",
    "        rows.append(top_words)\n",
    "    columns = [f'topic {i + 1}' for i in range(n_top_words)]\n",
    "    df1 = pd.DataFrame(rows, columns=columns)\n",
    "    return df1\n",
    "\n",
    "#2\n",
    "#将包含文本数据的numpy数组X输入到一个已经训练好的LDA主题模型model中\n",
    "def predict_to_data_frame(model: LatentDirichletAllocation, X: np.ndarray) -> pd.DataFrame:\n",
    "    matrix = model.transform(X)\n",
    "    columns = [f'P(topic {i + 1})' for i in range(len(model.components_))]\n",
    "    df1 = pd.DataFrame(matrix, columns=columns)\n",
    "    return df1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a517fe",
   "metadata": {},
   "source": [
    "### 4.保存结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5b7223eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 要输出的每个主题的前 n_top_words 个主题词数\n",
    "n_top_words = 50\n",
    "\n",
    "# 计算 n_top_words 个主题词\n",
    "top_words_df = top_words_data_frame(lda, tf_idf_vectorizer, n_top_words)\n",
    "\n",
    "# 保存 n_top_words 个主题词到 csv 文件中\n",
    "top_words_df.to_csv(\"D:/top_words.csv\", encoding='utf-8', index=None)\n",
    "\n",
    "# 转 tf_idf 为数组，以便后面使用它来对文本主题概率分布进行计算\n",
    "X = tf_idf.toarray()\n",
    "\n",
    "# 计算完毕主题概率分布情况\n",
    "predict_df = predict_to_data_frame(lda, X)\n",
    "\n",
    "# 保存文本主题概率分布到 csv 文件中\n",
    "predict_df.to_csv(\"D:/predict_topic.csv\", encoding='utf-8', index=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b495ba35",
   "metadata": {},
   "source": [
    "## 3.评论情感分析系统"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bc13275b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob #提供文本数据分析api\n",
    "from snownlp import SnowNLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "11e013b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      user_name     user_id  user_age  user_gender  user_province  user_city  \\\n",
      "0         w安默拉w  2033412777         0            2         370000   371300.0   \n",
      "1  橘生又落valentia  3727270134         0            0              0      100.0   \n",
      "2  橘生又落valentia  3727270134         0            0              0      100.0   \n",
      "3     竹苑Cecilia  6329599584         0            2         360000   361000.0   \n",
      "4         清风夜水寒  2073414099         0            0              0      100.0   \n",
      "\n",
      "   user_introduce                                            comment  \\\n",
      "0             NaN  第一次听以为是“一生反复一场大无畏梦境”，特别惊艳，后来看到原句才发现是“奔赴”，又觉得奔赴...   \n",
      "1  自在随心，想唱什么就唱什么～                                      怀念一波入坑曲[多多大哭]   \n",
      "2  自在随心，想唱什么就唱什么～                                 @山风没疯 哈哈哈哈哈哈哈哈哈哈（）   \n",
      "3             NaN                                   情绪内耗就来听琉璃真的可以治愈我   \n",
      "4             NaN                                           有疗愈效果，亲测   \n",
      "\n",
      "     comment_id  praise                 date  year  month  day  hour  \\\n",
      "0  6.040284e+09       0  2024-01-15 08:41:00  2024      1   15     8   \n",
      "1  6.040167e+09       0  2024-01-15 01:48:00  2024      1   15     1   \n",
      "2  6.040164e+09       0  2024-01-15 01:48:00  2024      1   15     1   \n",
      "3  6.037419e+09       2  2024-01-10 23:23:00  2024      1   10    23   \n",
      "4  6.037348e+09       6  2024-01-10 21:10:00  2024      1   10    21   \n",
      "\n",
      "   new_user_id province_name  \\\n",
      "0   2033412777           山东省   \n",
      "1   3727270134           NaN   \n",
      "2   3727270134           NaN   \n",
      "3   6329599584           江西省   \n",
      "4   2073414099           NaN   \n",
      "\n",
      "                                                 cut emotion_score  \n",
      "0  第一次 听 以为 是   一生 反复 一场 大无畏 梦境   特别 惊艳   后来 看到 原...      0.999554  \n",
      "1                                怀念 一波入 坑曲   多多 大哭        0.881019  \n",
      "2                             山风 没疯   哈哈哈哈 哈哈哈 哈哈哈        0.979541  \n",
      "3                          情绪 内耗 就 来 听 琉璃 真的 可以 治愈 我      0.938998  \n",
      "4                                       有疗 愈 效果   亲测      0.881358  \n"
     ]
    }
   ],
   "source": [
    "#Snownlp\n",
    "df['emotion_score'] = ''\n",
    "for i, row in df.iterrows():\n",
    "    text = row['cut']  # 获取文本数据\n",
    "    s = SnowNLP(text)\n",
    "    score = s.sentiments\n",
    "\n",
    "    # 将情感得分添加到 DataFrame 中\n",
    "    df.at[i, 'emotion_score'] = score\n",
    "# 查看 DataFrame\n",
    "print(df.head())\n",
    "df.to_excel('D:/emotion_score.xlsx', index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13de6cf1",
   "metadata": {},
   "source": [
    "获取情感平均值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "14e7d65a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average emotion value is: 0.715972532741754\n"
     ]
    }
   ],
   "source": [
    "average_emotion = df['emotion_score'].mean()\n",
    "\n",
    "print(f'The average emotion value is: {average_emotion}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5f812330",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('D:/total_已建模.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c87c3a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
